{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Xp63AVWmMkbF"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from xgboost import XGBClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, RocCurveDisplay, ConfusionMatrixDisplay\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from imblearn.over_sampling import SMOTE\n","import seaborn as sns\n","import shap\n","from tqdm.notebook import tqdm\n","\n","# 한글 폰트 설치 및 설정\n","!apt-get update -qq\n","!apt-get install fonts-nanum* -qq\n","\n","import matplotlib.font_manager as fm\n","font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n","fm.fontManager.addfont(font_path)\n","plt.rc('font', family='NanumGothic')\n","\n","# 데이터 로드\n","file_path = '/content/drive/MyDrive/2024/train_OutlierRemoval.csv'  # Colab에 업로드한 파일 경로를 사용하세요\n","data = pd.read_csv(file_path)\n","\n","# 불필요한 열 제거\n","data = data.drop(columns=['Unnamed: 0', 'ID'])\n","\n","# 사용할 특성 선택 및 흡연 여부(label) 컬럼 설정\n","features = ['헤모글로빈', '혈청 크레아티닌', '충치', '키(cm)', '몸무게(kg)', '중성 지방', '시력', '공복 혈당', '요 단백', '콜레스테롤', '저밀도지단백', '나이', '고밀도지단백', '간 효소율']\n","X = data[features]\n","y = data['label']\n","\n","# 결측치 처리 및 데이터 스케일링\n","print(\"Preprocessing data...\")\n","numeric_imputer = SimpleImputer(strategy='mean')\n","scaler = StandardScaler()\n","\n","X = pd.DataFrame(numeric_imputer.fit_transform(X), columns=X.columns)\n","X[features] = scaler.fit_transform(X[features])\n","\n","# SMOTE를 사용한 오버샘플링\n","print(\"Applying SMOTE...\")\n","smote = SMOTE(random_state=0)\n","X_resampled, y_resampled = smote.fit_resample(X, y)\n","\n","# 학습 데이터와 테스트 데이터로 분리\n","print(\"Splitting data...\")\n","X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=0)\n","\n","# 개별 모델 설정\n","print(\"Setting up models...\")\n","logreg = LogisticRegression(max_iter=10000)\n","random_forest = RandomForestClassifier(random_state=0)\n","xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n","\n","# 파라미터 그리드 설정 (축소된 범위)\n","param_grid = {\n","    'logreg__C': [0.1, 1],\n","    'logreg__penalty': ['l2'],\n","    'logreg__solver': ['liblinear'],\n","    'rf__n_estimators': [50, 100],\n","    'xgb__n_estimators': [100, 200],\n","    'xgb__max_depth': [3, 5],\n","    'xgb__learning_rate': [0.1, 0.2]\n","}\n","\n","# 앙상블 모델 설정\n","ensemble_model = VotingClassifier(estimators=[\n","    ('logreg', logreg),\n","    ('rf', random_forest),\n","    ('xgb', xgb)\n","], voting='soft', n_jobs=-1)\n","\n","# 그리드 서치 설정 및 실행\n","print(\"Running GridSearchCV...\")\n","grid_search = GridSearchCV(ensemble_model, param_grid, cv=StratifiedKFold(n_splits=3), scoring='accuracy', n_jobs=1, verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","# 최적 하이퍼파라미터 출력\n","print(f\"Best Parameters: {grid_search.best_params_}\")\n","\n","# 최적 모델 학습\n","print(\"Training the best model...\")\n","best_model = grid_search.best_estimator_\n","\n","# 교차 검증 점수 계산 및 결과 출력\n","print(\"Calculating cross-validation scores...\")\n","logreg_scores = cross_val_score(best_model.named_estimators_['logreg'], X_train, y_train, cv=StratifiedKFold(n_splits=3), scoring='accuracy')\n","rf_scores = cross_val_score(best_model.named_estimators_['rf'], X_train, y_train, cv=StratifiedKFold(n_splits=3), scoring='accuracy')\n","xgb_scores = cross_val_score(best_model.named_estimators_['xgb'], X_train, y_train, cv=StratifiedKFold(n_splits=3), scoring='accuracy')\n","\n","print(\"Logistic Regression CV Accuracy Scores:\")\n","for fold_idx, score in enumerate(logreg_scores, 1):\n","    print(f\"Fold {fold_idx}: {score:.4f}\")\n","print(f\"Mean Logistic Regression CV Accuracy: {np.mean(logreg_scores):.4f}\")\n","\n","print(\"Random Forest CV Accuracy Scores:\")\n","for fold_idx, score in enumerate(rf_scores, 1):\n","    print(f\"Fold {fold_idx}: {score:.4f}\")\n","print(f\"Mean Random Forest CV Accuracy: {np.mean(rf_scores):.4f}\")\n","\n","print(\"XGBoost CV Accuracy Scores:\")\n","for fold_idx, score in enumerate(xgb_scores, 1):\n","    print(f\"Fold {fold_idx}: {score:.4f}\")\n","print(f\"Mean XGBoost CV Accuracy: {np.mean(xgb_scores):.4f}\")\n","\n","# 최적 모델 평가\n","print(\"Evaluating the best model...\")\n","y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n","y_pred = best_model.predict(X_test)\n","\n","fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n","roc_auc = auc(fpr, tpr)\n","\n","print(f\"ROC AUC: {roc_auc}\")\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","print(\"Confusion Matrix:\")\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","# 성능 지표 계산\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy:.4f}')\n","print(f'Precision: {precision:.4f}')\n","print(f'Recall: {recall:.4f}')\n","print(f'F1 Score: {f1:.4f}')\n","print(f'ROC AUC: {roc_auc:.4f}')\n","\n","# 혼돈 행렬 시각화\n","ConfusionMatrixDisplay(conf_matrix).plot(cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# ROC 곡선 시각화\n","RocCurveDisplay.from_estimator(best_model, X_test, y_test)\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.show()\n","\n","# 분포도 시각화\n","sns.histplot(y_test, kde=False, label='Actual', color='blue', alpha=0.6)\n","sns.histplot(y_pred, kde=False, label='Predicted', color='orange', alpha=0.6)\n","plt.legend()\n","plt.title('Distribution of Actual vs Predicted')\n","plt.show()\n","\n","# 로지스틱 회귀 계수 시각화\n","logreg_coef = pd.Series(best_model.named_estimators_['logreg'].coef_[0], index=features)\n","logreg_coef = logreg_coef.sort_values()\n","plt.figure(figsize=(10, 6))\n","logreg_coef.plot(kind='barh')\n","plt.title('Logistic Regression Coefficients')\n","plt.show()\n","\n","# 랜덤 포레스트 피처 중요도 시각화\n","rf_importance = pd.Series(best_model.named_estimators_['rf'].feature_importances_, index=features)\n","rf_importance = rf_importance.sort_values()\n","plt.figure(figsize=(10, 6))\n","rf_importance.plot(kind='barh')\n","plt.title('Random Forest Feature Importance')\n","plt.show()\n","\n","# XGBoost 피처 중요도 시각화\n","xgb_importance = pd.Series(best_model.named_estimators_['xgb'].feature_importances_, index=features)\n","xgb_importance = xgb_importance.sort_values()\n","plt.figure(figsize=(10, 6))\n","xgb_importance.plot(kind='barh')\n","plt.title('XGBoost Feature Importance')\n","plt.show()\n","\n","# SHAP 값 계산 및 시각화\n","print(\"Calculating SHAP values...\")\n","explainer = shap.TreeExplainer(best_model.named_estimators_['xgb'])\n","shap_values = explainer.shap_values(X_test)\n","\n","shap.summary_plot(shap_values, X_test, plot_type=\"bar\", feature_names=features)\n","shap.summary_plot(shap_values, X_test, feature_names=features)\n"]}]}